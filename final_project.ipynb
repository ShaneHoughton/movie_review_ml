{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame the Problem and Look at the Big Picture\n",
    "=====================================\n",
    "\n",
    "1. **Define the objective in business terms:** We have been hired by Magic Films for their new streaming service which provides access to a wide variety of movies. \n",
    "2. **How will your solution be used?** They want to eventually know what movies should be displayed and promoted on the homepage to attract users based on written reviews from viewers as well as what movies to remove from the website to save money on licensing fees.\n",
    "3. **What solutions are in place?** For certain businesses such as the restaurant business, they try and identify certain keywords in reviews to find out what they are doing well and their customers like and what they can improve on.\n",
    "4. **How should you frame this problem?** This is a supervised binary classification problem. Based on words and how they are used in a review we want to determine whether the review was `Positive` or `Negative`.\n",
    "5. **How should performance be measured? Is the performance measure aligned with the business objective?** Because we are not to identify as many positives as we can by risking false positives and we are not trying to identify all the negatives we can, we believe we should use F1 score to find a middle ground. We want to reduce false positives and false negatives as equally as possible.\n",
    "6. **What would be the minimum performance needed to reach the business objective?** We would like to get our score as close to 1.0 as possible. A goal is to get at least .85 or better.\n",
    "7. **What are comparable problems? Can you reuse experience or tools?** We have had multi-classification experience with the MNIST data set for trying to decide what a number a written digit or what article of clothing something is. More importantly, we previously created a binary-classification model that would try to predict whether there would be an early spring or not. We would not be able to directly reuse this model in particular because we are trying to identify words within a review to determine if the review was positive or not.\n",
    "8. **Is human expertise available?** We do not have anyone readily available but we are advised on the Readme to contact Andrew Maas, the organizer of the dataset, with any questions. We can also try and contact the user who uploaded the dataset to Kaggle.\n",
    "9. **How would you solve the problem manually?** The manual approach would to be to parse up the reviews and try and filter out words with negative or positive connotations in order to decide whether a review is positive or negative. This could be a problem with sarcastic reviews and reviews with spelling errors or slang.\n",
    "10. **List the assumptions you (or others) have made so far. Verify assumptions if possible.** We are assuming that the data set is all primarily english and has no spelling mistakes or errors in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading and splitting data\n",
    "def load_data(data):\n",
    "    \"\"\"Loads a dataset\"\"\"\n",
    "    return pd.read_csv(data)\n",
    "\n",
    "\n",
    "def split_labels(data, label_feature):\n",
    "    \"\"\"\n",
    "    Split the given column of of the data, returning the full data set (without that\n",
    "    feature) and the split off feature.\n",
    "    \"\"\"\n",
    "    return data.drop(columns=label_feature), data[label_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Data\n",
    "==========\n",
    "\n",
    "1. **List the data you need and how much you need:** We have a dataset of IMDB movie reviews containing a combniation of positive and negative reviews for movies.\n",
    "2. **Find and document where you can get that data:** We got the data from: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "3. **Get access authorizations**: No authorization needed, the data is free to access on Kaggle.\n",
    "4. **Create a workspace**: This notebook.\n",
    "5. **Get the data**: Downloaded from Kaggle.\n",
    "6. **Convert the data to a format you can easily manipulate**: Already in CSV files so easy to use.\n",
    "7. **Ensure sensitive information is deleted or protected**: Data contains no sensitive information.\n",
    "8. **Check the size and type of data (time series, geographical, …)**: This categorical data set contains reviews written in text as well as a binary attribute indicating whether the review was positive or not. It contains 50,000 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('imdb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 50000\n",
       "unique                                                49582\n",
       "top       Loved today's show!!! It was a variety and not...\n",
       "freq                                                      5\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`review` is a text object containing a written review of a certain film. There are 50000 of these reviews but only 49582 are unique. This will be the main feature that we will try and derive meaning and sentiment from as well as create new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        50000\n",
       "unique           2\n",
       "top       positive\n",
       "freq         25000\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sentiment` is our <b>target feature</b> and is a binary categorical variable. This is the label that indicates whether a review is a positive one or negative. A review is labeled simply as `positive` or `negative`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19961, 20039)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = train_set[train_set['sentiment']=='positive'].reset_index()\n",
    "negatives = train_set[train_set['sentiment']=='negative'].reset_index()\n",
    "len(positives), len(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About half of the reviews in the training set are positive and the other half is negative, so both types are about equally represented. And it is also nice to know there are not any missing values in the dataset, which is important with just two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45278</td>\n",
       "      <td>A touching love story reminiscent of In the M...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30219</td>\n",
       "      <td>The people who are bad-mouthing this film are ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14290</td>\n",
       "      <td>I own the miniseries on DVD because I love thi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24755</td>\n",
       "      <td>ELVIRA, MISTRESS OF THE DARK (1988)&lt;br /&gt;&lt;br /...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48038</td>\n",
       "      <td>Considering all the teen films like \"the Break...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30239</td>\n",
       "      <td>The recent history of Hollywood remakes of gho...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7195</td>\n",
       "      <td>While I had wanted to se this film since the f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3579</td>\n",
       "      <td>Star Trek: Hidden Frontier is a long-running i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34095</td>\n",
       "      <td>The romance of the movie, which is also its ma...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10441</td>\n",
       "      <td>Viewed this the other night on cable on-demand...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             review sentiment\n",
       "0  45278  A touching love story reminiscent of In the M...  positive\n",
       "1  30219  The people who are bad-mouthing this film are ...  positive\n",
       "2  14290  I own the miniseries on DVD because I love thi...  positive\n",
       "3  24755  ELVIRA, MISTRESS OF THE DARK (1988)<br /><br /...  positive\n",
       "4  48038  Considering all the teen films like \"the Break...  positive\n",
       "5  30239  The recent history of Hollywood remakes of gho...  positive\n",
       "6   7195  While I had wanted to se this film since the f...  positive\n",
       "7   3579  Star Trek: Hidden Frontier is a long-running i...  positive\n",
       "8  34095  The romance of the movie, which is also its ma...  positive\n",
       "9  10441  Viewed this the other night on cable on-demand...  positive"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a positive review, giving us an idea of what this kind of review will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'A Tale of Two Sisters', or 'Janghwa, Hongryeon', is a true masterpiece. Brilliant psychological thriller, heart-wrenching drama, and gripping horror all wrapped up in one beautifully orchestrated package. From the intricate plot, to the beautiful cinematography, to the absolutely perfect casting, every aspect of this film is extraordinary.<br /><br />For fear of revealing too much concerning the plot, I will just say it is very satisfying. While it may appear to be a little difficult to understand at first, it does a good job of explaining things in the end. And whether you prefer psychological thriller, drama, or horror, I promise you will not be disappointed.<br /><br />From a technical standpoint, its nearly flawless. The set, the cinematography, lighting, and especially the soundtrack, all are captivating. The waltz seemed an odd choice at first, but proved to be an ingenious choice.<br /><br />As for the casting, we're talking absolute perfection. I'm Su-jeong is totally convincing as the defiant, yet troubled Su-mi. Mun Keun- yeong is equally convincing as her emotionally traumatized sister Su-yeon. These two girls were magical on the screen. I will certainly be looking into their other films. Yeom Jeong-ah is deceitfully cheerful and hauntingly evil as the stepmother. Finally, Kap-su Kim gives an excellent performance as the weary, broken father.<br /><br />I truly love this film. If you have yet to see 'A Tale Of Two Sisters', I strongly recommend locating a copy. It is a real gem, worthy of anyone's collection.<br /><br />(10/10)\""
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives['review'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a negative review, giving us an idea of what this kind of review will look like.\n",
    "It should be noted that there appear to be `HTML` elements peppered in some of the positive and negative reviews. In this example we see a `<br />` tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the html with a regular expression substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'A Tale of Two Sisters', or 'Janghwa, Hongryeon', is a true masterpiece. Brilliant psychological thriller, heart-wrenching drama, and gripping horror all wrapped up in one beautifully orchestrated package. From the intricate plot, to the beautiful cinematography, to the absolutely perfect casting, every aspect of this film is extraordinary.  For fear of revealing too much concerning the plot, I will just say it is very satisfying. While it may appear to be a little difficult to understand at first, it does a good job of explaining things in the end. And whether you prefer psychological thriller, drama, or horror, I promise you will not be disappointed.  From a technical standpoint, its nearly flawless. The set, the cinematography, lighting, and especially the soundtrack, all are captivating. The waltz seemed an odd choice at first, but proved to be an ingenious choice.  As for the casting, we're talking absolute perfection. I'm Su-jeong is totally convincing as the defiant, yet troubled Su-mi. Mun Keun- yeong is equally convincing as her emotionally traumatized sister Su-yeon. These two girls were magical on the screen. I will certainly be looking into their other films. Yeom Jeong-ah is deceitfully cheerful and hauntingly evil as the stepmother. Finally, Kap-su Kim gives an excellent performance as the weary, broken father.  I truly love this film. If you have yet to see 'A Tale Of Two Sisters', I strongly recommend locating a copy. It is a real gem, worthy of anyone's collection.  (10/10)\""
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re as re\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>',' ', string)\n",
    "    return result\n",
    "\n",
    "positives['review'] = positives['review'].apply(lambda cw : remove_tags(cw))\n",
    "positives['review'][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Detective Dave Robicheaux is trying to link the murder of a local hooker to New Orleans mobster Julie Balboni. But during his investigation Robicheaux is led into a series of surreal encounters with a troop of Confederate soldiers??, What a awful plot and it was worser than i had expected. it was real slow and had minimal skill in the acting i could not watch through it it was waste of my time. Another FLOP, i would give it under 1 if i could please people don't waste your time its 1:42m of wast-full time. Actor Elrod Sykes and his girlfriend driving under the influence. As Dave takes Elod to the station the actor tells Dave he found some skeletal remains while on the set of a movie he is filming\""
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives['review'][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin breaking down reviews and what words might entail a negative or positive review we might want to try and see what words are most popularly used..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      267096\n",
       "and      137254\n",
       "a        128990\n",
       "of       120498\n",
       "to       103814\n",
       "          ...  \n",
       "being      5020\n",
       "it.        5005\n",
       "made       4994\n",
       "never      4944\n",
       "make       4927\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(positives['review']).lower().split()).value_counts()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as expected, this approach will result in finding a lot of the words will be prepositions, determiners, conjuctions or very basic words found in speech. What might be more helpful is identifying key phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try creating a new feature such as review length and see if there is any interesting patterns for negative and postitive review lengths. This may not be extremely helpful because we want to know the sentiment of a review based on its contents but with 2 features creating new ones could be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 502)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives['review_len'] = positives['review'].str.len()\n",
    "len(positives['review'][0]), positives['review_len'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2328, 2328)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives['review_len'] = negatives['review'].str.len()\n",
    "len(negatives['review'][0]), negatives['review_len'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19961.000000</td>\n",
       "      <td>19961.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25153.452182</td>\n",
       "      <td>1305.741195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14421.388610</td>\n",
       "      <td>1021.584432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12688.000000</td>\n",
       "      <td>683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25128.000000</td>\n",
       "      <td>954.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37694.000000</td>\n",
       "      <td>1587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49995.000000</td>\n",
       "      <td>13604.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index    review_len\n",
       "count  19961.000000  19961.000000\n",
       "mean   25153.452182   1305.741195\n",
       "std    14421.388610   1021.584432\n",
       "min        0.000000     81.000000\n",
       "25%    12688.000000    683.000000\n",
       "50%    25128.000000    954.000000\n",
       "75%    37694.000000   1587.000000\n",
       "max    49995.000000  13604.000000"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20039.000000</td>\n",
       "      <td>20039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24929.297370</td>\n",
       "      <td>1291.453067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14460.407721</td>\n",
       "      <td>943.250004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12323.500000</td>\n",
       "      <td>705.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24887.000000</td>\n",
       "      <td>971.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37438.000000</td>\n",
       "      <td>1565.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000000</td>\n",
       "      <td>8969.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index    review_len\n",
       "count  20039.000000  20039.000000\n",
       "mean   24929.297370   1291.453067\n",
       "std    14460.407721    943.250004\n",
       "min        3.000000     32.000000\n",
       "25%    12323.500000    705.000000\n",
       "50%    24887.000000    971.000000\n",
       "75%    37438.000000   1565.500000\n",
       "max    49999.000000   8969.000000"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately there does not seem like any apparent major differences between the two, but it looks like positive reviews are longer on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = pd.concat([positives, negatives], axis=0)['review_len']\n",
    "lengths.hist(bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be improved with a log transformation. Also its seems that someone wrote a particularly lengthy review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(lengths).hist(bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be a helpful metric but what we truly want is a way to detect the sentiment in reviews based off the phrases in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Data\n",
    "====\n",
    "1. **Data cleaning:** Fix/remove outliers (optional); We might possibly have to remove really long reviews? But that might not be necessary for evaluating sentiment.\n",
    "2. **Feature selection** (optional): Drop attributes that provide no useful information for the task\n",
    "3. **Feature engineering, where appropriate:** Discretize continuous features; Decompose features (categorical, date/time, ...), Add promising transformations of features (log(𝑥𝑥), √𝑥𝑥, 𝑥𝑥2, ...); Aggregate features into promising new features\n",
    "4. **Feature scaling:** standardize or normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vocabulary transformer?\n",
    "# save that vocabulary...\n",
    "# make a transformer that makes reviews into tokens \n",
    "# save that vocabulary to encode text\n",
    "# train the model on NN\n",
    "# https://machinelearningmastery.com/deep-learning-bag-of-words-model-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with Keras\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# remove punctuation from review and lowercase it\n",
    "\tdoc = doc.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# filter out short tokens\n",
    "\ttokens = [word for word in tokens if len(word) > 1]\n",
    "\treturn tokens\n",
    "\n",
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(doc, vocab):\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# update counts\n",
    "\tvocab.update(tokens)\n",
    " \n",
    "# load all docs in a dataframe\n",
    "def process_df_docs(df, vocab):\n",
    "\t# walk through all files in the folder\n",
    "\tfor entry in df['review']:\n",
    "\t\t# add doc to vocab\n",
    "\t\tadd_doc_to_vocab(entry, vocab)\n",
    "  \n",
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(doc, vocab):\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# filter by vocab\n",
    "\ttokens = [w for w in tokens if w in vocab]\n",
    "\treturn ' '.join(tokens)\n",
    " \n",
    "# load all docs in a directory\n",
    "def process_dir_docs(df, vocab):\n",
    "\tlines = list()\n",
    "\t# walk through all files in the folder\n",
    "\tfor entry in df['review']:\n",
    "\t\tline = doc_to_line(entry, vocab)\n",
    "\t\t# add to list\n",
    "\t\tlines.append(line)\n",
    "\treturn lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = clean_doc(positives['review'][42])\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154314\n",
      "[('the', 531274), ('and', 256205), ('of', 230364), ('to', 213250), ('is', 168136), ('in', 147400), ('it', 122418), ('this', 119423), ('that', 109035), ('br', 91147), ('was', 76246), ('as', 72998), ('for', 69259), ('with', 69191), ('movie', 66600), ('but', 65413), ('film', 59651), ('on', 53316), ('not', 48035), ('you', 47500), ('are', 46503), ('his', 45644), ('have', 44078), ('be', 42265), ('he', 41225), ('one', 40911), ('its', 39074), ('at', 37280), ('all', 36219), ('by', 35226), ('an', 34318), ('they', 33132), ('from', 32399), ('who', 32193), ('so', 31633), ('like', 31152), ('just', 27997), ('or', 27922), ('her', 27343), ('about', 27097), ('if', 26861), ('has', 26392), ('out', 26172), ('some', 24817), ('there', 24465), ('what', 24402), ('good', 22759), ('very', 22227), ('when', 22126), ('more', 22080)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#154314\n",
    "# define vocab\n",
    "vocab = Counter()\n",
    "# add all docs to vocab\n",
    "process_df_docs(train_set, vocab)\n",
    "# print the size of the vocab\n",
    "print(len(vocab))\n",
    "# print the top words in the vocab\n",
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71482\n"
     ]
    }
   ],
   "source": [
    "min_occurane = 2\n",
    "tokens = [k for k,c in vocab.items() if c >= min_occurane]\n",
    "print(len(tokens)) #71482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19961 20039\n"
     ]
    }
   ],
   "source": [
    "#19961 20039\n",
    "# load the vocabulary\n",
    "vocab_filename = 'vocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "# load all training reviews\n",
    "positive_lines = process_dir_docs(positives, vocab)\n",
    "negative_lines = process_dir_docs(negatives, vocab)\n",
    "# summarize what we have\n",
    "print(len(positive_lines), len(negative_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5039, 4961)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_positives = test_set[test_set['sentiment']=='positive'].reset_index()\n",
    "test_negatives = test_set[test_set['sentiment']=='negative'].reset_index()\n",
    "len(test_positives), len(test_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/houghtons@moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb Cell 46'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=48'>49</a>\u001b[0m \u001b[39m# load all training reviews\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=49'>50</a>\u001b[0m positive_lines \u001b[39m=\u001b[39m process_docs(positives, vocab)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=50'>51</a>\u001b[0m negative_lines \u001b[39m=\u001b[39m process_docs(negatives, vocab)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=51'>52</a>\u001b[0m \u001b[39m# create the tokenizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=52'>53</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mTokenizer()\n",
      "\u001b[1;32m/Users/houghtons@moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb Cell 46'\u001b[0m in \u001b[0;36mprocess_docs\u001b[0;34m(df, vocab)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=35'>36</a>\u001b[0m \u001b[39m# walk through all files in the folder\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=37'>38</a>\u001b[0m \t\u001b[39m# load and clean the doc\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=38'>39</a>\u001b[0m \tline \u001b[39m=\u001b[39m doc_to_line(entry, vocab)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=39'>40</a>\u001b[0m \t\u001b[39m# add to list\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=40'>41</a>\u001b[0m \tlines\u001b[39m.\u001b[39mappend(line)\n",
      "\u001b[1;32m/Users/houghtons@moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb Cell 46'\u001b[0m in \u001b[0;36mdoc_to_line\u001b[0;34m(doc, vocab)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdoc_to_line\u001b[39m(doc, vocab):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=26'>27</a>\u001b[0m \t\u001b[39m# clean doc\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=27'>28</a>\u001b[0m \ttokens \u001b[39m=\u001b[39m clean_doc(doc)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=28'>29</a>\u001b[0m \t\u001b[39m# filter by vocab\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=29'>30</a>\u001b[0m \ttokens \u001b[39m=\u001b[39m [w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m w \u001b[39min\u001b[39;00m vocab]\n",
      "\u001b[1;32m/Users/houghtons@moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb Cell 46'\u001b[0m in \u001b[0;36mclean_doc\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclean_doc\u001b[39m(doc):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=14'>15</a>\u001b[0m \t\u001b[39m# remove punctuation from review and lowercase it\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=15'>16</a>\u001b[0m \tdoc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mtranslate(\u001b[39mstr\u001b[39;49m\u001b[39m.\u001b[39;49mmaketrans(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, string\u001b[39m.\u001b[39;49mpunctuation))\u001b[39m.\u001b[39mlower()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=16'>17</a>\u001b[0m \t\u001b[39m# split into tokens by white space\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/houghtons%40moravian.edu/Desktop/cs390/final/movie_review_ml/final_project.ipynb#ch0000046?line=17'>18</a>\u001b[0m \ttokens \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39msplit()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# remove punctuation from review and lowercase it\n",
    "\tdoc = doc.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# filter out short tokens\n",
    "\ttokens = [word for word in tokens if len(word) > 1]\n",
    "\treturn tokens\n",
    "\n",
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(doc, vocab):\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# filter by vocab\n",
    "\ttokens = [w for w in tokens if w in vocab]\n",
    "\treturn ' '.join(tokens)\n",
    "\n",
    "# load all docs in a dataframe\n",
    "def process_docs(df, vocab):\n",
    "\tlines = list()\n",
    "\t# walk through all files in the folder\n",
    "\tfor entry in df['review']:\n",
    "\t\t# load and clean the doc\n",
    "\t\tline = doc_to_line(entry, vocab)\n",
    "\t\t# add to list\n",
    "\t\tlines.append(line)\n",
    "\treturn lines\n",
    "\n",
    "# load the vocabulary\n",
    "vocab_filename = 'vocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "# load all training reviews\n",
    "positive_lines = process_docs(positives, vocab)\n",
    "negative_lines = process_docs(negatives, vocab)\n",
    "# create the tokenizer\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "docs = negative_lines + positive_lines\n",
    "tokenizer.fit_on_texts(docs)\n",
    "# encode training data set\n",
    "Xtrain = tokenizer.texts_to_matrix(docs, mode='freq')\n",
    "ytrain = np.array([0 for _ in range(20000)] + [1 for _ in range(20000)])\n",
    "\n",
    "# load all test reviews\n",
    "positive_lines = process_docs(test_positives, vocab)\n",
    "negative_lines = process_docs(test_negatives, vocab)\n",
    "docs = negative_lines + positive_lines\n",
    "# encode training data set\n",
    "Xtest = tokenizer.texts_to_matrix(docs, mode='freq')\n",
    "ytest = np.array([0 for _ in range(5000)] + [1 for _ in range(5000)])\n",
    "\n",
    "n_words = Xtest.shape[1]\n",
    "# define network\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 48.460001\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(Xtrain, ytrain, epochs=5, verbose=2)\n",
    "# evaluate\n",
    "loss, acc = model.evaluate(Xtest, ytest, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Sklearn\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 93003)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_set['review'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3282"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 93003)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(train_set['review'], train_set['sentiment'])\n",
    "\n",
    "predicted = text_clf.predict(test_set['review'])\n",
    "np.mean(predicted == test_set['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__alpha', 'clf__average', 'clf__class_weight', 'clf__early_stopping', 'clf__epsilon', 'clf__eta0', 'clf__fit_intercept', 'clf__l1_ratio', 'clf__learning_rate', 'clf__loss', 'clf__max_iter', 'clf__n_iter_no_change', 'clf__n_jobs', 'clf__penalty', 'clf__power_t', 'clf__random_state', 'clf__shuffle', 'clf__tol', 'clf__validation_fraction', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'clf__alpha': 2.5750000000000002e-05,\n",
       "  'tfidf__norm': 'l2',\n",
       "  'tfidf__sublinear_tf': True},\n",
       " 0.899875)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_param_grid = [{\n",
    "    'tfidf__norm':['l1', 'l2'],\n",
    "    'tfidf__sublinear_tf':[True, False],\n",
    "    'clf__alpha': np.linspace(1e-6, 1e-4, 5),\n",
    "}]\n",
    "sgd_search = GridSearchCV(\n",
    "    text_clf, text_param_grid,\n",
    "    cv=5, scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "sgd_search.fit(train_set['review'], train_set['sentiment'])\n",
    "sgd_search.best_params_, sgd_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
