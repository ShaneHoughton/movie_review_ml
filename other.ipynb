{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame the Problem and Look at the Big Picture\n",
    "=====================================\n",
    "\n",
    "1. **Define the objective in business terms:** We have been hired by Magic Films for their new streaming service which provides access to a wide variety of movies. \n",
    "2. **How will your solution be used?** They want to eventually know what movies should be displayed and promoted on the homepage to attract users based on written reviews from viewers as well as what movies to remove from the website to save money on licensing fees.\n",
    "3. **What solutions are in place?** For certain businesses such as the restaurant business, they try and identify certain keywords in reviews to find out what they are doing well and their customers like and what they can improve on.\n",
    "4. **How should you frame this problem?** This is a supervised binary classification problem. Based on words and how they are used in a review we want to determine whether the review was `Positive` or `Negative`.\n",
    "5. **How should performance be measured? Is the performance measure aligned with the business objective?** Because we are not to identify as many positives as we can by risking false positives and we are not trying to identify all the negatives we can, we believe we should use F1 score to find a middle ground. We want to reduce false positives and false negatives as equally as possible.\n",
    "6. **What would be the minimum performance needed to reach the business objective?** We would like to get our score as close to 1.0 as possible. A goal is to get at least .85 or better.\n",
    "7. **What are comparable problems? Can you reuse experience or tools?** We have had multi-classification experience with the MNIST data set for trying to decide what a number a written digit or what article of clothing something is. More importantly, we previously created a binary-classification model that would try to predict whether there would be an early spring or not. We would not be able to directly reuse this model in particular because we are trying to identify words within a review to determine if the review was positive or not.\n",
    "8. **Is human expertise available?** We do not have anyone readily available but we are advised on the Readme to contact Andrew Maas, the organizer of the dataset, with any questions. We can also try and contact the user who uploaded the dataset to Kaggle.\n",
    "9. **How would you solve the problem manually?** The manual approach would to be to parse up the reviews and try and filter out words with negative or positive connotations in order to decide whether a review is positive or negative. This could be a problem with sarcastic reviews and reviews with spelling errors or slang.\n",
    "10. **List the assumptions you (or others) have made so far. Verify assumptions if possible.** We are assuming that the data set is all primarily english and has no spelling mistakes or errors in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading and splitting data\n",
    "def load_data(data):\n",
    "    \"\"\"Loads a dataset\"\"\"\n",
    "    return pd.read_csv(data)\n",
    "\n",
    "\n",
    "def split_labels(data, label_feature):\n",
    "    \"\"\"\n",
    "    Split the given column of the data, returning the full data set (without that\n",
    "    feature) and the split off feature.\n",
    "    \"\"\"\n",
    "    return data.drop(columns=label_feature), data[label_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Data\n",
    "==========\n",
    "\n",
    "1. **List the data you need and how much you need:** We have a dataset of IMDB movie reviews containing a combniation of positive and negative reviews for movies.\n",
    "2. **Find and document where you can get that data:** We got the data from: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "3. **Get access authorizations**: No authorization needed, the data is free to access on Kaggle.\n",
    "4. **Create a workspace**: This notebook.\n",
    "5. **Get the data**: Downloaded from Kaggle.\n",
    "6. **Convert the data to a format you can easily manipulate**: Already in CSV files so easy to use.\n",
    "7. **Ensure sensitive information is deleted or protected**: Data contains no sensitive information.\n",
    "8. **Check the size and type of data (time series, geographical, …)**: This categorical data set contains reviews written in text as well as a binary attribute indicating whether the review was positive or not. It contains 50,000 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('imdb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 50000\n",
       "unique                                                49582\n",
       "top       Loved today's show!!! It was a variety and not...\n",
       "freq                                                      5\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`review` is a text object containing a written review of a certain film. There are 50000 of these reviews but only 49582 are unique. This will be the main feature that we will try and derive meaning and sentiment from as well as create new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        50000\n",
       "unique           2\n",
       "top       positive\n",
       "freq         25000\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sentiment` is our <b>target feature</b> and is a binary categorical variable. This is the label that indicates whether a review is a positive one or negative. A review is labeled simply as `positive` or `negative`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42, shuffle=True, stratify=data['sentiment'])\n",
    "train_set, valid_set = train_test_split(train_set, test_size=0.1, random_state=42, shuffle=True, stratify=train_set['sentiment'])\n",
    "X_train, y_train = split_labels(train_set, 'sentiment')\n",
    "X_test, y_test = split_labels(test_set, 'sentiment')\n",
    "X_valid, y_valid = split_labels(valid_set, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 18000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = train_set[train_set['sentiment']=='positive'].reset_index()\n",
    "negatives = train_set[train_set['sentiment']=='negative'].reset_index()\n",
    "len(positives), len(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About half of the reviews in the training set are positive and the other half is negative, so both types are about equally represented. And it is also nice to know there are not any missing values in the dataset, which is important with just two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33890</td>\n",
       "      <td>This is an excellent stand-up DVD! Eddie Izzar...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35186</td>\n",
       "      <td>This movie has always been a favorite of mine ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41267</td>\n",
       "      <td>This is an excellent, fast paced thriller by W...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21302</td>\n",
       "      <td>I think this movie is my favorite movie. I am ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13974</td>\n",
       "      <td>Best Years of Our Lives is a film that slipped...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24506</td>\n",
       "      <td>It's 1913. A studio prop boy spies the actress...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25859</td>\n",
       "      <td>\"Showtime\" is a funny film starring funnymen R...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32515</td>\n",
       "      <td>This is a great TV miniseries of a classic nov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26441</td>\n",
       "      <td>This is one of my favorite family movies. Love...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34065</td>\n",
       "      <td>If you think about it, it's nearly unbelievabl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             review sentiment\n",
       "0  33890  This is an excellent stand-up DVD! Eddie Izzar...  positive\n",
       "1  35186  This movie has always been a favorite of mine ...  positive\n",
       "2  41267  This is an excellent, fast paced thriller by W...  positive\n",
       "3  21302  I think this movie is my favorite movie. I am ...  positive\n",
       "4  13974  Best Years of Our Lives is a film that slipped...  positive\n",
       "5  24506  It's 1913. A studio prop boy spies the actress...  positive\n",
       "6  25859  \"Showtime\" is a funny film starring funnymen R...  positive\n",
       "7  32515  This is a great TV miniseries of a classic nov...  positive\n",
       "8  26441  This is one of my favorite family movies. Love...  positive\n",
       "9  34065  If you think about it, it's nearly unbelievabl...  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a positive review, giving us an idea of what this kind of review will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Iran, the Islamic Revolution has shaped all parts of life, including everyday things. But people still go on living their lives, generally just doing the things you'd expect, like go to soccer matches to cheer on the national team as it's in the running to qualify for the World Cup. Except women aren't allowed to go to the soccer stadium to watch the game.<br /><br />A frequently funny little film follows the small group of women that were caught sneaking into the soccer stadium and the little group of bored soldiers assigned to guard them in a holding pen just outside the stadium. The absurdity of the situation, the simple wish of these women to cheer on the team (nothing subversive there), and little human touches about the lives of everyone adds up to quite a fine comment on humanity versus the ideology.<br /><br />Amateurish acting, good script and dialogue, a really enjoyable film. Bend It Like Beckham, sort of - a warm heart and a joy in the daily interests and pleasures of people.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives['review'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a negative review, giving us an idea of what this kind of review will look like.\n",
    "It should be noted that there appear to be `HTML` elements peppered in some of the positive and negative reviews. In this example we see a `<br />` tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the html with a regular expression substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Iran, the Islamic Revolution has shaped all parts of life, including everyday things. But people still go on living their lives, generally just doing the things you'd expect, like go to soccer matches to cheer on the national team as it's in the running to qualify for the World Cup. Except women aren't allowed to go to the soccer stadium to watch the game.  A frequently funny little film follows the small group of women that were caught sneaking into the soccer stadium and the little group of bored soldiers assigned to guard them in a holding pen just outside the stadium. The absurdity of the situation, the simple wish of these women to cheer on the team (nothing subversive there), and little human touches about the lives of everyone adds up to quite a fine comment on humanity versus the ideology.  Amateurish acting, good script and dialogue, a really enjoyable film. Bend It Like Beckham, sort of - a warm heart and a joy in the daily interests and pleasures of people.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re as re\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>',' ', string)\n",
    "    return result\n",
    "\n",
    "positives['review'] = positives['review'].apply(lambda review : remove_tags(review))\n",
    "negatives['review'] = negatives['review'].apply(lambda review : remove_tags(review))\n",
    "\n",
    "positives['review'][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is not great cinema. The film is cliche ridden and in many places it is a copy of the original Carrie. The parallels with the original film are striking but with an added improbability about the telekenetic powers being congenital.  I can't say that I disliked the film because it at least passed a couple of hours ... but these were passed as one would read an undemanding book on a long train journey. That book would not be great literature but would absorb one for a while and be forgotten soon afterwards in that it would blend in with the numerous other cliche ridden books. Likewise the film was okay whilst it lasted but is perhaps forgettable. At least I think it is. I cant remember much about it now!!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives['review'][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin breaking down reviews and what words might entail a negative or positive review we might want to try and see what words are most popularly used..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      239956\n",
       "and      123672\n",
       "a        116261\n",
       "of       108634\n",
       "to        93468\n",
       "          ...  \n",
       "made       4542\n",
       "being      4496\n",
       "make       4460\n",
       "it.        4449\n",
       "never      4425\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(positives['review']).lower().split()).value_counts()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as expected, this approach will result in finding a lot of the words will be prepositions, determiners, conjuctions or very basic words found in speech. What might be more helpful is identifying key phrases, or less than the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "completely    937\n",
       "rest          934\n",
       "start         934\n",
       "friends       933\n",
       "episode       933\n",
       "             ... \n",
       "drama         743\n",
       "white         742\n",
       "directed      741\n",
       "course,       739\n",
       "including     739\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(positives['review']).lower().split()).value_counts()[400:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "me.            994\n",
       "is,            994\n",
       "bad,           992\n",
       "performance    991\n",
       "line           986\n",
       "              ... \n",
       "bunch          794\n",
       "running        789\n",
       "cheap          789\n",
       "writing        785\n",
       "finally        784\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(negatives['review']).lower().split()).value_counts()[400:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we get to words used frequently but less than the most common, we see ones that may be more telling like bad cheap writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try creating a new feature such as review length and see if there is any interesting patterns for negative and postitive review lengths. This may not be extremely helpful because we want to know the sentiment of a review based on its contents but with 2 features creating new ones could be useful. But we will try and create many new features by trying to implement `Bag of Words` eventuallly so it probably won't be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 704)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives['review_len'] = positives['review'].str.len()\n",
    "len(positives['review'][0]), positives['review_len'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1537, 1537)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives['review_len'] = negatives['review'].str.len()\n",
    "len(negatives['review'][0]), negatives['review_len'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18000.000000</td>\n",
       "      <td>18000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24994.566611</td>\n",
       "      <td>1302.842056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14364.484819</td>\n",
       "      <td>1009.492811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12564.750000</td>\n",
       "      <td>684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24976.500000</td>\n",
       "      <td>954.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37433.250000</td>\n",
       "      <td>1587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49992.000000</td>\n",
       "      <td>13604.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index    review_len\n",
       "count  18000.000000  18000.000000\n",
       "mean   24994.566611   1302.842056\n",
       "std    14364.484819   1009.492811\n",
       "min        0.000000     65.000000\n",
       "25%    12564.750000    684.000000\n",
       "50%    24976.500000    954.000000\n",
       "75%    37433.250000   1587.000000\n",
       "max    49992.000000  13604.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18000.000000</td>\n",
       "      <td>18000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24800.754222</td>\n",
       "      <td>1279.153778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14397.278761</td>\n",
       "      <td>938.617424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12352.500000</td>\n",
       "      <td>697.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24722.500000</td>\n",
       "      <td>958.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37151.250000</td>\n",
       "      <td>1551.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000000</td>\n",
       "      <td>8729.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index    review_len\n",
       "count  18000.000000  18000.000000\n",
       "mean   24800.754222   1279.153778\n",
       "std    14397.278761    938.617424\n",
       "min        3.000000     41.000000\n",
       "25%    12352.500000    697.000000\n",
       "50%    24722.500000    958.000000\n",
       "75%    37151.250000   1551.000000\n",
       "max    49999.000000   8729.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately there does not seem like any apparent major differences between the two, but it looks like positive reviews are longer on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = pd.concat([positives, negatives], axis=0)['review_len']\n",
    "lengths.hist(bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be improved with a log transformation. Also its seems that someone wrote a particularly lengthy review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(lengths).hist(bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be a helpful metric but what we truly want is a way to detect the sentiment in reviews based off processing the words in them instead of length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Data\n",
    "====\n",
    "1. **Data cleaning:** Fix/remove outliers (optional); We might possibly have to remove really long reviews? But that might not be necessary for evaluating sentiment.\n",
    "2. **Feature selection** (optional): Drop attributes that provide no useful information for the task\n",
    "3. **Feature engineering, where appropriate:** Discretize continuous features; Decompose features (categorical, date/time, ...), Add promising transformations of features (log(𝑥𝑥), √𝑥𝑥, 𝑥𝑥2, ...); Aggregate features into promising new features\n",
    "4. **Feature scaling:** standardize or normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words\n",
    "===========\n",
    "In order to solve our problem of having few features we are going to try and implement a Bag of Words approach. This will help our number of features grow exponentially, and we will do this as we prepare our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, max_df=6000, lowercase=True, stop_words='english')\n",
    "vectorizer.fit(X_train['review'])\n",
    "X_train_vectorized = vectorizer.transform(X_train['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes a sparse matrix where each column is a specific word, each row is a review, and each entry has a 1 if the review contains that word. Similar concept to oneHot encoding but for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SGD: 0.8532222222222222\n",
      "Accuracy for Log_Reg: 0.8669444444444444\n"
     ]
    }
   ],
   "source": [
    "# Trying some classifiers on the vectorized data\n",
    "for clf_name, classifier in zip(['SGD', 'Log_Reg'],[SGDClassifier(), LogisticRegression(max_iter=200)]):\n",
    "    scores = cross_val_score(classifier, X_train_vectorized, y_train, cv=3, scoring='accuracy')\n",
    "    print('Accuracy for {}: {}'.format(clf_name, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SKlearn\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 88840)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_set['review'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3101"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 88840)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = np.where(y_train == 'positive', 1, 0)\n",
    "y_test_int = np.where(y_test == 'positive', 1, 0)\n",
    "y_valid_int = np.where(y_valid == 'positive', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveHTMLTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer class that removes HTML tags from strings\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X.apply(lambda review : remove_tags(review))\n",
    "        return X\n",
    "\n",
    "    def remove_tags(string):\n",
    "        result = re.sub('<.*?>',' ', string)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24839    The movie starts off as we see a footage of a ...\n",
       "33890    This is an excellent stand-up DVD! Eddie Izzar...\n",
       "4692     Though I've yet to review the movie in about t...\n",
       "34202    As a big fan of David Mamet's films and plays,...\n",
       "29985    This move is bad on so many levels I don't eve...\n",
       "                               ...                        \n",
       "17522    Despite being quite far removed from my expect...\n",
       "23897    Holy crap this movie was bad. I watched it jus...\n",
       "43410    This movie is horrible. Everything in it has b...\n",
       "24457    Sorry, I don't have much time to write. I am n...\n",
       "15389    I really wanted to like this movie, but ended ...\n",
       "Name: review, Length: 36000, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_trans = RemoveHTMLTransformer()\n",
    "html_trans.transform(train_set['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84125"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('HTML_remover', RemoveHTMLTransformer()),\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train['review'], y_train_int)\n",
    "\n",
    "predicted = text_clf.predict(X_valid['review'])\n",
    "np.mean(predicted == y_valid_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'HTML_remover', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__alpha', 'clf__average', 'clf__class_weight', 'clf__early_stopping', 'clf__epsilon', 'clf__eta0', 'clf__fit_intercept', 'clf__l1_ratio', 'clf__learning_rate', 'clf__loss', 'clf__max_iter', 'clf__n_iter_no_change', 'clf__n_jobs', 'clf__penalty', 'clf__power_t', 'clf__random_state', 'clf__shuffle', 'clf__tol', 'clf__validation_fraction', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'clf__alpha': 5.05e-05,\n",
       "  'tfidf__norm': 'l2',\n",
       "  'tfidf__sublinear_tf': True,\n",
       "  'vect__max_df': 1.0,\n",
       "  'vect__stop_words': None},\n",
       " 0.8982777777777777)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_param_grid = [{\n",
    "    'tfidf__norm':['l1', 'l2'],\n",
    "    'tfidf__sublinear_tf':[True, False],\n",
    "    'clf__alpha': np.linspace(1e-6, 1e-4, 5),\n",
    "    'vect__stop_words':[None, 'english'],\n",
    "    'vect__max_df':[0.5, 0.75, 1.0],\n",
    "}]\n",
    "sgd_search = GridSearchCV(\n",
    "    text_clf, text_param_grid,\n",
    "    cv=5, scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "sgd_search.fit(X_train['review'], y_train_int)\n",
    "sgd_search.best_params_, sgd_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84175"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_clf = Pipeline([\n",
    "    ('HTML_remover', RemoveHTMLTransformer()),\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "rfc_clf.fit(X_train['review'], y_train_int)\n",
    "\n",
    "predicted = rfc_clf.predict(X_valid['review'])\n",
    "np.mean(predicted == y_valid_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with Keras\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = np.where(y_train == 'positive', 1, 0)\n",
    "y_test_int = np.where(y_test == 'positive', 1, 0)\n",
    "y_valid_int = np.where(y_valid == 'positive', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 21794)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, max_df=6000, lowercase=True, stop_words='english')\n",
    "vectorizer.fit(X_train['review'])\n",
    "X_train_vectorized = vectorizer.transform(X_train['review'])\n",
    "X_valid_vectorized = vectorizer.transform(X_valid['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 21794)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_15\" (type Sequential).\n    \n    Input 0 of layer \"batch_normalization_26\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 500)\n    \n    Call arguments received:\n      • inputs=<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f1a1ab753d0>\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlecun_normal\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid_vectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_int\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/refactored-robot/lib64/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqlczon9c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/refactored-robot/lib64/python3.9/site-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_15\" (type Sequential).\n    \n    Input 0 of layer \"batch_normalization_26\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 500)\n    \n    Call arguments received:\n      • inputs=<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f1a1ab753d0>\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(None,21794)))\n",
    "model.add(keras.layers.Dense(500, activation='elu', kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    model.add(keras.layers.Dense(200, activation=keras.activations.relu, kernel_initializer=\"lecun_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# model.add(keras.layers.Dense(10, activation='sigmoid', kernel_initializer='lecun_normal'))\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid', kernel_initializer='lecun_normal'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_vectorized, y_train_int, epochs=10, verbose=1, validation_data=(X_valid_vectorized, y_valid_int), callbacks=[keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9348 - accuracy: 0.8693: 0s - loss: 0.9420 - accuracy: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9347573518753052, 0.8693000078201294]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test['review'])\n",
    "model.evaluate(X_test_vectorized, y_test_int)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
